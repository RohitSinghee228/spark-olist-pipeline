{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffebe5b7-6c76-476b-a4c1-1bb76c330a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.adaptive.enabled\",\"true\")         # AQE ON\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")      # tune as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f8b5f80-7e4a-4ba6-97ef-d81520b0a8dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, date_format, col\n",
    "\n",
    "# read orders CSV (adjust path)\n",
    "orders = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\") \\\n",
    "    .csv(\"/FileStore/olist/olist_orders_dataset.csv\")\n",
    "\n",
    "# create purchase_date and yyyy-mm partition column\n",
    "orders = orders.withColumn(\"purchase_date\", to_date(col(\"order_purchase_timestamp\"))) \\\n",
    "               .withColumn(\"purchase_yyyy_mm\", date_format(col(\"purchase_date\"), \"yyyy-MM\"))\n",
    "\n",
    "# write as Delta to bronze (set maxRecordsPerFile to control file sizing)\n",
    "orders.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"maxRecordsPerFile\", 500000) \\\n",
    "    .partitionBy(\"purchase_yyyy_mm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab06307-f242-4db3-a853-5d4f95ea188c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, lower, initcap\n",
    "\n",
    "customers = spark.read.format(\"delta\").load(\"/mnt/delta/bronze/customers\")\n",
    "customers = customers.withColumn(\"customer_city\", initcap(trim(lower(col(\"customer_city\"))))) \\\n",
    "                     .withColumn(\"customer_state\", initcap(trim(lower(col(\"customer_state\")))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48424738-2f72-4c11-ac76-746b6f6e5566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27de3105-9267-4628-9db9-af89f531376e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16521f7-a1f4-490c-bbf1-d0d7e4347301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "w = Window.partitionBy(\"customer_id\").orderBy(desc(\"creation_date\"))\n",
    "dedup_customers = customers.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\")==1).drop(\"rn\")\n",
    "dedup_customers.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/delta/silver/customers\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-09-11 16_53_12",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
